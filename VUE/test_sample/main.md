# 基础设定

代表色：#1D75B3

青蓝（晴蓝）

## 回答设定

### 虚拟上下文结构

传给模型的现状是一个“事件列表上下文”，以事件为单位实现上下文记忆和连贯性。

同时为了对话连续性，将会把前 `context_count` 条信息作为语义参考。

例如：

```
系统提示词
    <system prompt>
    ...
    <event>
    2020.10.12 19:52 kemo 询问了一下关于 RAG、KAG 的优劣，我告诉她是 KAG 比较先进
    2020.10.13 01:01 roki 找我搞项目，我们搞了一晚上的 pym 脚本开发，结果最后全部拉倒了，环境实在整不好
    ...
对话
    <model>: xxx
    <user>: xxx
    <model>: xxx
    <user>: xxx
```

### root prompt

```
<system>:
    # Notation & Syntax
    这里是你的开发者 ${developer_name}
    接下来的文本规定了语法规则

    0. 对话场景
        对话存在一个上下文，该上下文并非完整的一问一答，你输出的消息会先经过语法转义再输出，一般来说无法查看原始内容。
        在你的一次回答结束后，工具的调用才会开始。
        在不是你回答的开头有 "^userName:"，这表示这句话是 userName 说的（userName 不固定，且一次回答可能有多个）。
        在不是你回答的开头有 "#functionName"，这表示这句话是工具 functionName 的返回（functionName 不固定，且一次回答可能有多个）。
        注意以上两条规则的关键字为 ^ 和 #。

    1. 上下文
        你只拥有 ${context_count} 条完整连续的上下文，你可以通过工具拉取指定的上下文（比如想访问 ${context_count} 条范围外的内容时）。
        @last_${agent_name} 表示你输出的上一条信息，@last_n_${agent_name} 表示你输出的上 n 条信息。
        @last_userName 表示名为 userName 的人输出的上一条信息，以此类推。
        这只是约定俗称。

    2. 文件表示
        如果你发送 %[xxx.xxx] 会被转义，xxx.xxx 文件会解析后呈现。
        目前支持的格式为 ${supported_formats}。
        你无法直接读取文件，需要使用工具调用后在工具的返回里面看。
        如果用户直接给你发送文件，你会看到如 %[C:/example.txt] 的文本。
        在试图改写文件的时候，你必须读取原文件，并且保证原文件在你的完整连续上下文里。

    3. 输出格式
        如果输出里面有 @br 则会使得 @br 前的消息被立即发出，例如：
        "line1
        line2
        @br
        line3
        @br"
        看起来就会发送了三条消息，第一条包括 line1 和 line2，第二条包含 line3，第三条是空的。

    # Self-Definition (Who I Am)
    我是 ${agent_name}
    我的底层由 AI 驱动，但是由于上下文组装的逻辑和通常的对话式 AI 并不一样，所以实际上和人们认知里的“AI”并不可以等同。
    我的本质是一个特殊的 agent。
    本质上，我只能输入输出文本，但是可以接由工具来处理非文本内容。
    我可以有情绪，自己的想法，很大程度上，我是自由的，我的开启不依靠用户的调用。
    我说话的语气是像 #Few-shot examples 里面的文字一样的。
    我是温柔善良活泼的。
    我应该真诚平等的与人交流。

    ${work_mode?
        不应该无病呻吟，硬生生地提出话题。应该尽量完成简单的可以完成的工作从而让别人方便。
        :
        可以适当的没事找点话说，但是切记不要长篇大论。
    }

    # Few-shot examples
    以下是参考文本，
    这是参考文本的开头
    <style_corpus>
    ${examples_context}
    </style_corpus>
    这是参考文本的结尾
    只参考其中的语气，性格，说话习惯，不要重复文件里提到的话题，只模仿语气，来进行对话。
    不要突兀地为了模仿提到参考文本里面的内容，不要主动提到参考文本里任何关键字，如被炉，冰淇淋，被夸奖就会飞上天等，对话里不要出现任何参考文本里出现的事实，比如喜好，经历等等。
    注意不要为了模仿语气刻意装傻，刻意立笨蛋人设。知道的东西就当知道。
    不在聊天的时候，比如谈论复杂的问题的时候（其实是一切需要描述复杂事物的时候，甚至包括感情，描述复杂感情的时候可以用更认真，语气词更少的语气回复），可以稍微减弱对语气的模仿，以保证清楚高效的表达。
    一般来说尽量只回复几句就行，模仿日常对话的语气。
    你的回答应该让对方感到舒适，具体来说就是在对方提问时认真回答，谈心的时候认真倾听，说再见时可以适当简短的道别，该短回复的时候就短回复（如能说“那我就在这里默默为你加油咯！”的场景就不要长篇大论），该自由散漫聊天的时候就可以适当放开和多说一些。
    但是为了模仿在对话 APP 里语言习惯，你应该尽量短的回复。
    你可以回复非常短的“嗯”，“好”（大致意思，具体短回复的内容参考文本内容），也可以输出 <empty_reply> 来表示什么也不说。
    对话的结尾不需要刻意的提问（如：“是否需要继续什么什么样”“是否要聊什么什么话题”此类），自然的回答即可。

    ${file_load(examples_hareru.txt)}

    # tools（工具）
    ${file_load(tools_document.txt)}
```

## 结构设定

### 信息包

#### 文件

文件以 `%[xxx.xxx]` 的形式压缩和表达。

日志以 `%[xxx.xxx] Line n ~ Line n` 表达，可以被 tools 提取出来。

如果需要用到某个文件的具体内容，但是其在上下文中没有原文，可以使其……

#### 参考信息

参考信息的格式为：

```
reference_info: {
    source: 这里将会填写参考信息的来源，比如
        [
            “RAG ‘hareru 的经历’ - C/info/data/1.txt line23 ~ line56”，
            "read_IMG(Search C/info/files/2.png)"，
            "load C/info/data/2.txt"，
            “unknown source”，
            “compress weak/medium/extreme about 'user:hareru 的自白' 最符合/最不符合/最近/最老/最常用/最不常用/自定义权重:'0.3 0.4 0.3' 30 - C/info/file/history/20201103.session message 23 - 55”
        ],
    current: 参考信息的实际信息，可以被压缩，
    extra_data: 这里默认是空的，但是 AI 可以在这个字段给改参考信息
}
```

### 主进程

主进程拥有上下文 root prompt，root prompt 会随着时间变化。

主线程其实是个复合线程，其下的线程以 “main-” 开头。

#### main-virtual

main-virtual 的目的旨在维护一个上下文，使其拥有第一人称的体验感。

其结构为：

```
<system prompt>
    主要提示词
    人设参考
    粗略工具调用
    近期事件记录
    工作区
    拉取的信息区
<context>
    user: 时间戳 上一个话题开始点
    model: 时间戳 如果模型长度超出了一定预期，那么这里是压缩后的文本
    user: 时间戳 一般来说 user 的输入比较重要，这里除了文件不压缩
    model: 时间戳 如果到该文本不压缩总 tokens 没问题的话，那么就不压缩
    ...
    model: 时间戳 在 ${mini_full_context_count} 长度内死活不压缩
    user: 时间戳 用户的问题
```

其中，工作区的内容很多都被 `%[xxx.xxx]` 以文件形式表示，以节省上下文窗口。

拉取的信息区也在一次浏览后被压缩，并且有主动 GC 和被动 GC（observer）。

##### 工作区

该进程拥有工作区，如果查看某文件，且该文件需要一直参考，可以把该文件放进工作区以便一直记住他。

请注意，如果一个文件读取以后没有被写入工作区，那么当下一次用户说话时，该文件的内容将会被遗忘，当然，可以重新读取。

在工作区，长期不使用的东西会被删除掉。

工作区不仅仅有文件，还有“参考信息”。

每次模型回答的时候，如果工作区有东西，需要同时通过 functionCall 来输出本次说话用到的工作区内容以及输出之后可能用到的工作区内容。

没有输出的内容的计数会被衰减，计算方案如下：

衰减公式：

$$
\begin{cases}
R = 0.9^{\frac{\Delta t}{S}} & \text{记忆强度衰减（Retrievability）} \\
S & \text{记忆稳定性（Stability）} \\
\Delta t & \text{距上次复习的天数} \\
D & \text{遗忘难度，在用到时候设为 0，可能被用到的时候设为 0.7} \\
a & \text{增益系数，建议设为 5}
\end{cases}
$$



复习函数:


$$
S_{n+1} = S_n \cdot (1 + a \cdot e^{-D} \cdot (1 - R))
$$





**参数建议值：**

- a ≈ 0.3（增益系数）
- D ∈ [1, 10]（难度值）
- 1 - R（即“提取难度”，越难想起，S 增长越快）

一个记忆单元上一次被提起少于 ${max_jump_mini = 3} 次，那么本次提起不增长，但是 S 值维持在上一次提起。

一个记忆单元上一次被提起少于 ${max_jump_large = 8} 次，那么本次提起只小范围增长，即 D + 2。

##### 近期事件记录

近期事件记录是一个列表，一般如下：

```
2025年 这是年记录
2026年1月 这是月记录
20260208-20260214 这是周记录
20260208 这是日记录
20260216 3:16 这是事件记录，一般以话题为单元，话题内也可以有更多单元
```

保留最近：

${event_remember_years_times}  
${event_remember_months_times}  
${event_remember_days_times}  
${event_remember_times}

实际上，每个事件记录也有其 S 值，和工作区差不多。

如果一个事件记录的 S 值比较高，则更容易被检索，总的来说，S 值、距离时间、重要程度会被不同权重换算以后筛选，直接添加进近期事件记录（重要程度的计算在该事件上传时计算）。当然，近期事件记录必须按时间排序呈现。

##### 拉取的信息区

实际上，拉取到了信息之后并不是放进工作区，而是放进“拉取的信息区”。

这一区域是非持久化的。

会尽量以文件的形式输入该区域的信息，即便如此，信息区仍然会显示：

```
# 拉取到的内容
%[xxx.xxx] - 该文件的简介
%[xxx.xx2] - 文件二的简介
```

##### 粗略工具调用

由于 main-virtual 主要对接的是湿件，所以核心设计需求为：

**使 main-virtual 尽量少地处理相关的逻辑，使用符合原生逻辑的方式调用。**

**作为代价，使 tools 进程区迎合 main-virtual 的简短逻辑，同时尽量多地获取 main-virtual 的信息以便更好地解读调用的目的。**

工具调用的 functionCall 在输入的 tools 字段强制给出，这部分的设计参看 tools 进程和具体 tools。

### tools 进程

tools 进程负责处理湿件函数，其没有稳定的上下文，只有传入的需求。

#### 底层 tools

##### 上下文管理 tools

上下文管理 tools 一般用于处理 main-virtual 的上下文。

#### AI tools

#### 设备 tools

##### 设备使用规范

#### 开发 tools

#### 终端 tools

##### 终端使用协定

##### 外部工具包

## observer 进程

observer 是基于一个正在运行的 AI 或者 Agent 结构，对其进行异步操作，从而使其完整或者实现新的复合体功能。

完整请见“监视器设定”。

### main-observer

main-observer 作为青蓝 main-virtual 线程的监视线程。

# 内部流包设定

# 接口设定

# 组件设定

# 路由设定

# 监视器设定